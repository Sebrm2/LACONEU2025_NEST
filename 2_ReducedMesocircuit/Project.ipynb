{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5822b6-9f59-4589-ba7f-c144ae2fc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a7467c-ba27-454a-998a-37628f1c440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              -- N E S T --\n",
      "  Copyright (C) 2004 The NEST Initiative\n",
      "\n",
      " Version: 3.7.0\n",
      " Built: May 19 2024 15:53:53\n",
      "\n",
      " This program is provided AS IS and comes with\n",
      " NO WARRANTY. See the file LICENSE for details.\n",
      "\n",
      " Problems or suggestions?\n",
      "   Visit https://www.nest-simulator.org\n",
      "\n",
      " Type 'nest.help()' to find out more about NEST.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nest\n",
    "nest.set_verbosity('M_ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ed77666-3564-41fc-84ee-3430718a2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exc_inh_matrix(val_exc, val_inh, num_pops):\n",
    "    \"\"\"Creates a matrix for excitatory and inhibitory values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    val_exc\n",
    "        Excitatory value.\n",
    "    val_inh\n",
    "        Inhibitory value.\n",
    "    num_pops\n",
    "        Number of populations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matrix\n",
    "        A matrix of of size (num_pops x num_pops).\n",
    "\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((num_pops, num_pops))\n",
    "    matrix[:, 0:num_pops:2] = val_exc\n",
    "    matrix[:, 1:num_pops:2] = val_inh\n",
    "    return matrix\n",
    "\n",
    "\n",
    "net_dict = {\n",
    "    # factor to scale the number of neurons\n",
    "    \"N_scaling\": 0.01,\n",
    "    # factor to scale the indegrees\n",
    "    \"K_scaling\": 0.01,\n",
    "    # neuron model\n",
    "    \"neuron_model\": \"iaf_psc_exp\",\n",
    "    # names of the simulated neuronal populations\n",
    "    \"populations\": [\"L2E\", \"L2I\", \"L3E\", \"L3I\", \"L4E\", \"L4I\", \"L5E\", \"L5I\", \"L6E\", \"L6I\"],\n",
    "    # number of neurons in the different populations (same order as\n",
    "    # 'populations')\n",
    "    \"full_num_neurons\": np.array([20683, 5834, 20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948]),\n",
    "    # mean rates of the different populations in the non-scaled version of the\n",
    "    # microcircuit (in spikes/s; same order as in 'populations');\n",
    "    # necessary for the scaling of the network.\n",
    "    # The values were obtained by running this PyNEST microcircuit without MPI,\n",
    "    # 'local_num_threads' 4 and both 'N_scaling' and 'K_scaling' set to 1.\n",
    "    #\n",
    "    # Since these rates were only taken from one simulation, they alone are not sufficient for verification.\n",
    "    # For that, rates should be compared to mean values over multiple runs with different RNG seeds.\n",
    "    \"full_mean_rates\": np.array([0.903, 2.965, 0.903, 2.965, 4.414, 5.876, 7.569, 8.633, 1.105, 7.829]),\n",
    "    # connection probabilities (the first index corresponds to the targets\n",
    "    # and the second to the sources)\n",
    "    \"conn_probs\": np.array(\n",
    "        [\n",
    "            [0.1009, 0.1689, 0.1009, 0.1689, 0.0437, 0.0818, 0.0323, 0.0, 0.0076, 0.0],\n",
    "            [0.1346, 0.1371, 0.1346, 0.1371, 0.0316, 0.0515, 0.0755, 0.0, 0.0042, 0.0],\n",
    "            [0.1009, 0.1689, 0.1009, 0.1689, 0.0437, 0.0818, 0.0323, 0.0, 0.0076, 0.0],\n",
    "            [0.1346, 0.1371, 0.1346, 0.1371, 0.0316, 0.0515, 0.0755, 0.0, 0.0042, 0.0],\n",
    "            [0.0077, 0.0059, 0.0077, 0.0059, 0.0497, 0.135, 0.0067, 0.0003, 0.0453, 0.0],\n",
    "            [0.0691, 0.0029, 0.0691, 0.0029, 0.0794, 0.1597, 0.0033, 0.0, 0.1057, 0.0],\n",
    "            [0.1004, 0.0622, 0.1004, 0.0622, 0.0505, 0.0057, 0.0831, 0.3726, 0.0204, 0.0],\n",
    "            [0.0548, 0.0269, 0.0548, 0.0269, 0.0257, 0.0022, 0.06, 0.3158, 0.0086, 0.0],\n",
    "            [0.0156, 0.0066, 0.0156, 0.0066, 0.0211, 0.0166, 0.0572, 0.0197, 0.0396, 0.2252],\n",
    "            [0.0364, 0.001, 0.0364, 0.001, 0.0034, 0.0005, 0.0277, 0.008, 0.0658, 0.1443],\n",
    "        ]\n",
    "    ),\n",
    "    # mean amplitude of excitatory postsynaptic potential (in mV)\n",
    "    \"PSP_exc_mean\": 0.15,\n",
    "    # relative standard deviation of the weight\n",
    "    \"weight_rel_std\": 0.1,\n",
    "    # relative inhibitory weight\n",
    "    \"g\": -4,\n",
    "    # mean delay of excitatory connections (in ms)\n",
    "    \"delay_exc_mean\": 1.5,\n",
    "    # mean delay of inhibitory connections (in ms)\n",
    "    \"delay_inh_mean\": 0.75,\n",
    "    # relative standard deviation of the delay of excitatory and\n",
    "    # inhibitory connections\n",
    "    \"delay_rel_std\": 0.5,\n",
    "    # turn Poisson input on or off (True or False)\n",
    "    # if False: DC input is applied for compensation\n",
    "    \"poisson_input\": True,\n",
    "    # indegree of external connections to the different populations (same order\n",
    "    # as in 'populations')\n",
    "    \"K_ext\": np.array([1600, 1500, 1600, 1500, 2100, 1900, 2000, 1900, 2900, 2100]),\n",
    "    # rate of the Poisson generator (in spikes/s)\n",
    "    \"bg_rate\": 8.0,\n",
    "    # delay from the Poisson generator to the network (in ms)\n",
    "    \"delay_poisson\": 1.5,\n",
    "    # initial conditions for the membrane potential, options are:\n",
    "    # 'original': uniform mean and standard deviation for all populations as\n",
    "    #             used in earlier implementations of the model\n",
    "    # 'optimized': population-specific mean and standard deviation, allowing a\n",
    "    #              reduction of the initial activity burst in the network\n",
    "    #              (default)\n",
    "    \"V0_type\": \"optimized\",\n",
    "    #thalamic poisson params\n",
    "    \"th_rate\": 120,\n",
    "    \"th_start\":200,\n",
    "    \"th_duration\":10,\n",
    "    \n",
    "    # parameters of the neuron model\n",
    "    \"neuron_params\": {\n",
    "        # membrane potential average for the neurons (in mV)\n",
    "        \"V0_mean\": {\"original\": -58.0, \"optimized\": [-68.28, -63.16, -68.28, -63.16, -63.33, -63.45, -63.11, -61.66, -66.72, -61.43]},\n",
    "        # standard deviation of the average membrane potential (in mV)\n",
    "        \"V0_std\": {\"original\": 10.0, \"optimized\": [5.36, 4.57, 5.36, 4.57, 4.74, 4.94, 4.94, 4.55, 5.46, 4.48]},\n",
    "        # reset membrane potential of the neurons (in mV)\n",
    "        \"E_L\": -65.0,\n",
    "        # threshold potential of the neurons (in mV)\n",
    "        \"V_th\": -50.0,\n",
    "        # membrane potential after a spike (in mV)\n",
    "        \"V_reset\": -65.0,\n",
    "        # membrane capacitance (in pF)\n",
    "        \"C_m\": 250.0,\n",
    "        # membrane time constant (in ms)\n",
    "        \"tau_m\": 10.0,\n",
    "        # time constant of postsynaptic currents (in ms)\n",
    "        \"tau_syn\": 0.5,\n",
    "        # refractory period of the neurons after a spike (in ms)\n",
    "        \"t_ref\": 2.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "# derive matrix of mean PSPs,\n",
    "# the mean PSP of the connection from L4E to L23E is doubled\n",
    "PSP_matrix_mean = get_exc_inh_matrix(\n",
    "    net_dict[\"PSP_exc_mean\"], net_dict[\"PSP_exc_mean\"] * net_dict[\"g\"], len(net_dict[\"populations\"])\n",
    ")\n",
    "PSP_matrix_mean[0, 2] = 2.0 * net_dict[\"PSP_exc_mean\"]\n",
    "\n",
    "updated_dict = {\n",
    "    # matrix of mean PSPs\n",
    "    \"PSP_matrix_mean\": PSP_matrix_mean,\n",
    "    # matrix of mean delays\n",
    "    \"delay_matrix_mean\": get_exc_inh_matrix(\n",
    "        net_dict[\"delay_exc_mean\"], net_dict[\"delay_inh_mean\"], len(net_dict[\"populations\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "net_dict.update(updated_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99aa62ac-cefd-4a56-9e94-4e73f93b1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_synapses_from_conn_probs(conn_probs, popsize1, popsize2):\n",
    "    \"\"\"Computes the total number of synapses between two populations from\n",
    "    connection probabilities.\n",
    "\n",
    "    Here it is irrelevant which population is source and which target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn_probs\n",
    "        Matrix of connection probabilities.\n",
    "    popsize1\n",
    "        Size of first population.\n",
    "    popsize2\n",
    "        Size of second population.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_synapses\n",
    "        Matrix of synapse numbers.\n",
    "    \"\"\"\n",
    "    prod = np.outer(popsize1, popsize2)\n",
    "    num_synapses = np.log(1.0 - conn_probs) / np.log((prod - 1.0) / prod)\n",
    "    return num_synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c94062ce-0bf4-4f78-9f45-c25d378e2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_num_synapses = num_synapses_from_conn_probs(\n",
    "            net_dict[\"conn_probs\"], net_dict[\"full_num_neurons\"], net_dict[\"full_num_neurons\"]\n",
    "        )\n",
    "\n",
    "num_synapses = np.round(\n",
    "            (full_num_synapses * net_dict[\"N_scaling\"] * net_dict[\"K_scaling\"])\n",
    "        ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "090d3c7f-9982-434c-a2a5-31266f5b083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postsynaptic_potential_to_current(C_m, tau_m, tau_syn):\n",
    "    r\"\"\"Computes a factor to convert postsynaptic potentials to currents.\n",
    "\n",
    "    The time course of the postsynaptic potential ``v`` is computed as\n",
    "    :math: `v(t)=(i*h)(t)`\n",
    "    with the exponential postsynaptic current\n",
    "    :math:`i(t)=J\\mathrm{e}^{-t/\\tau_\\mathrm{syn}}\\Theta (t)`,\n",
    "    the voltage impulse response\n",
    "    :math:`h(t)=\\frac{1}{\\tau_\\mathrm{m}}\\mathrm{e}^{-t/\\tau_\\mathrm{m}}\\Theta (t)`,\n",
    "    and\n",
    "    :math:`\\Theta(t)=1` if :math:`t\\geq 0` and zero otherwise.\n",
    "\n",
    "    The ``PSP`` is considered as the maximum of ``v``, i.e., it is\n",
    "    computed by setting the derivative of ``v(t)`` to zero.\n",
    "    The expression for the time point at which ``v`` reaches its maximum\n",
    "    can be found in Eq. 5 of [1]_.\n",
    "\n",
    "    The amplitude of the postsynaptic current ``J`` corresponds to the\n",
    "    synaptic weight ``PSC``.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Hanuschkin A, Kunkel S, Helias M, Morrison A and Diesmann M (2010)\n",
    "           A general and efficient method for incorporating precise spike times\n",
    "           in globally time-driven simulations.\n",
    "           Front. Neuroinform. 4:113.\n",
    "           DOI: `10.3389/fninf.2010.00113 <https://doi.org/10.3389/fninf.2010.00113>`__.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_m\n",
    "        Membrane capacitance (in pF).\n",
    "    tau_m\n",
    "        Membrane time constant (in ms).\n",
    "    tau_syn\n",
    "        Synaptic time constant (in ms).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PSC_over_PSP\n",
    "        Conversion factor to be multiplied to a `PSP` (in mV) to obtain a `PSC`\n",
    "        (in pA).\n",
    "\n",
    "    \"\"\"\n",
    "    sub = 1.0 / (tau_syn - tau_m)\n",
    "    pre = tau_m * tau_syn / C_m * sub\n",
    "    frac = (tau_m / tau_syn) ** sub\n",
    "\n",
    "    PSC_over_PSP = 1.0 / (pre * (frac**tau_m - frac**tau_syn))\n",
    "    return PSC_over_PSP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c9c6ab8-3bb0-400d-ac61-69090b6e00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weights_and_input_to_synapse_scaling(\n",
    "    full_num_neurons,\n",
    "    full_num_synapses,\n",
    "    K_scaling,\n",
    "    mean_PSC_matrix,\n",
    "    PSC_ext,\n",
    "    tau_syn,\n",
    "    full_mean_rates,\n",
    "    DC_amp,\n",
    "    poisson_input,\n",
    "    bg_rate,\n",
    "    K_ext,\n",
    "):\n",
    "    \"\"\"Adjusts weights and external input to scaling of indegrees.\n",
    "\n",
    "    The recurrent and external weights are adjusted to the scaling\n",
    "    of the indegrees. Extra DC input is added to compensate for the\n",
    "    scaling in order to preserve the mean and variance of the input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    full_num_neurons\n",
    "        Total numbers of neurons.\n",
    "    full_num_synapses\n",
    "        Total numbers of synapses.\n",
    "    K_scaling\n",
    "        Scaling factor for indegrees.\n",
    "    mean_PSC_matrix\n",
    "        Weight matrix (in pA).\n",
    "    PSC_ext\n",
    "        External weight (in pA).\n",
    "    tau_syn\n",
    "        Synaptic time constant (in ms).\n",
    "    full_mean_rates\n",
    "        Firing rates of the full network (in spikes/s).\n",
    "    DC_amp\n",
    "        DC input current (in pA).\n",
    "    poisson_input\n",
    "        True if Poisson input is used.\n",
    "    bg_rate\n",
    "        Firing rate of Poisson generators (in spikes/s).\n",
    "    K_ext\n",
    "        External indegrees.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PSC_matrix_new\n",
    "        Adjusted weight matrix (in pA).\n",
    "    PSC_ext_new\n",
    "        Adjusted external weight (in pA).\n",
    "    DC_amp_new\n",
    "        Adjusted DC input (in pA).\n",
    "\n",
    "    \"\"\"\n",
    "    PSC_matrix_new = mean_PSC_matrix / np.sqrt(K_scaling)\n",
    "    PSC_ext_new = PSC_ext / np.sqrt(K_scaling)\n",
    "\n",
    "    # recurrent input of full network\n",
    "    indegree_matrix = full_num_synapses / full_num_neurons[:, np.newaxis]\n",
    "    input_rec = np.sum(mean_PSC_matrix * indegree_matrix * full_mean_rates, axis=1)\n",
    "\n",
    "    DC_amp_new = DC_amp + 0.001 * tau_syn * (1.0 - np.sqrt(K_scaling)) * input_rec\n",
    "\n",
    "    if poisson_input:\n",
    "        input_ext = PSC_ext * K_ext * bg_rate\n",
    "        DC_amp_new += 0.001 * tau_syn * (1.0 - np.sqrt(K_scaling)) * input_ext\n",
    "    return PSC_matrix_new, PSC_ext_new, DC_amp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37bf544d-412a-4031-b42b-ac9d198a9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSC_over_PSP = postsynaptic_potential_to_current(\n",
    "            net_dict[\"neuron_params\"][\"C_m\"],\n",
    "            net_dict[\"neuron_params\"][\"tau_m\"],\n",
    "            net_dict[\"neuron_params\"][\"tau_syn\"],\n",
    "        )\n",
    "PSC_matrix_mean = net_dict[\"PSP_matrix_mean\"] * PSC_over_PSP\n",
    "PSC_ext = net_dict[\"PSP_exc_mean\"] * PSC_over_PSP\n",
    "DC_amp = np.zeros(10)\n",
    "PSC_matrix_mean, PSC_ext, DC_amp = adjust_weights_and_input_to_synapse_scaling(\n",
    "                net_dict[\"full_num_neurons\"],\n",
    "                full_num_synapses,\n",
    "                net_dict[\"K_scaling\"],\n",
    "                PSC_matrix_mean,\n",
    "                PSC_ext,\n",
    "                net_dict[\"neuron_params\"][\"tau_syn\"],\n",
    "                net_dict[\"full_mean_rates\"],\n",
    "                DC_amp,\n",
    "                net_dict[\"poisson_input\"],\n",
    "                net_dict[\"bg_rate\"],\n",
    "                net_dict[\"K_ext\"],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6446ecee-9e6a-4560-a11b-9aac1a15a207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20683,  5834, 20683,  5834, 21915,  5479,  4850,  1065, 14395,\n",
       "        2948])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_dict['full_num_neurons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09f8d55b-f7c1-4b19-aecc-d6257a0fdc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2068  583 2068  583 2192  548  485  106 1440  295]\n"
     ]
    }
   ],
   "source": [
    "num_neurons = np.round((net_dict[\"full_num_neurons\"] * net_dict[\"N_scaling\"])).astype(int)\n",
    "print(num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bc1e0195-7b1c-4886-8dd2-a8b5ef6e358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_thalamic_pulse = True #the thalamus only sends to layer 4,5,6\n",
    "th_radius = 0.5\n",
    "th_delay = 1.0\n",
    "th_weight = 500 * 1 #what is this weight\n",
    "th_rate = 100.\n",
    "th_start = 500.\n",
    "th_stop = 550."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e92bc513-d73b-46dc-9c38-c4827167088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest.ResetKernel()\n",
    "nest.rng_seed = 42\n",
    "nest.resolution = 0.1\n",
    "nest.local_num_threads = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c600d1dd-bb81-447c-8a0a-7aeaa8ada215",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = 4\n",
    "positions = nest.spatial.free(\n",
    "    pos=nest.random.uniform(min=-extent / 2.,\n",
    "                            max=extent / 2.),\n",
    "    edge_wrap=True,\n",
    "    extent=[extent, extent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51efb646-44f5-46dd-a5ef-7aa5f41d9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = []\n",
    "\n",
    "for i in np.arange(len(population_sizes)):\n",
    "    population = nest.Create(net_dict[\"neuron_model\"], population_sizes[i], positions=positions)\n",
    "\n",
    "    population.set(\n",
    "        tau_syn_ex=net_dict[\"neuron_params\"][\"tau_syn\"],\n",
    "        tau_syn_in=net_dict[\"neuron_params\"][\"tau_syn\"],\n",
    "        E_L=net_dict[\"neuron_params\"][\"E_L\"],\n",
    "        V_th=net_dict[\"neuron_params\"][\"V_th\"],\n",
    "        V_reset=net_dict[\"neuron_params\"][\"V_reset\"],\n",
    "        t_ref=net_dict[\"neuron_params\"][\"t_ref\"],\n",
    "        V_m=nest.random.normal(\n",
    "            net_dict[\"neuron_params\"][\"V0_mean\"][\"optimized\"][i],\n",
    "            net_dict[\"neuron_params\"][\"V0_std\"][\"optimized\"][i],\n",
    "        )    \n",
    "    )\n",
    "\n",
    "    populations.append(population)\n",
    "\n",
    "left_populations = populations\n",
    "right_populations = populations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fedeffa1-5467-4baf-8c8b-5677709e946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_region_populations(region_pops):\n",
    "    for i, target_pop in enumerate(region_pops):\n",
    "        for j, source_pop in enumerate(region_pops):\n",
    "            if num_synapses[i][j] >= 0.0:\n",
    "                # Define the connection rule\n",
    "                conn_dict_rec = {\"rule\": \"fixed_total_number\", \"N\": num_synapses[i][j]}\n",
    "\n",
    "                # Determine weight bounds\n",
    "                if PSC_matrix_mean[i][j] < 0:\n",
    "                    w_min = -np.inf\n",
    "                    w_max = 0.0\n",
    "                else:\n",
    "                    w_min = 0.0\n",
    "                    w_max = np.inf\n",
    "\n",
    "                # Synaptic parameters\n",
    "                syn_dict = {\n",
    "                    \"synapse_model\": \"static_synapse\",\n",
    "                    \"weight\": nest.math.redraw(\n",
    "                        nest.random.normal(\n",
    "                            mean=PSC_matrix_mean[i][j],\n",
    "                            std=abs(PSC_matrix_mean[i][j] * net_dict[\"weight_rel_std\"]),\n",
    "                        ),\n",
    "                        min=w_min,\n",
    "                        max=w_max,\n",
    "                    ),\n",
    "                    \"delay\": nest.math.redraw(\n",
    "                        nest.random.normal(\n",
    "                            mean=net_dict[\"delay_matrix_mean\"][i][j],\n",
    "                            std=(net_dict[\"delay_matrix_mean\"][i][j] * net_dict[\"delay_rel_std\"]),\n",
    "                        ),\n",
    "                        min=nest.resolution - 0.5 * nest.resolution,\n",
    "                        max=np.inf,\n",
    "                    ),\n",
    "                }\n",
    "\n",
    "                nest.Connect(source_pop, target_pop, conn_spec=conn_dict_rec, syn_spec=syn_dict)\n",
    "\n",
    "connect_region_populations(left_populations)\n",
    "connect_region_populations(right_populations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "29a7c34a-c76f-4cf6-afe7-8f17263efafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connections between two columns\n",
    "\n",
    "layer2_populations = [left_populations[1],right_populations[1]]\n",
    "layer3_populations = [left_populations[1],right_populations[1]]\n",
    "layer6_populations = [left_populations[8],right_populations[8]]\n",
    "\n",
    "connect_region_populations(layer2_populations)\n",
    "connect_region_populations(layer3_populations)\n",
    "connect_region_populations(layer6_populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743365b2-94f4-4487-88b8-e1c9b58479a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poisson\n",
    "\n",
    "ext_indegrees = np.round((net_dict[\"K_ext\"] * net_dict[\"K_scaling\"])).astype(int)\n",
    "poisson_bg_input = nest.Create(\"poisson_generator\", n=len(population_sizes))\n",
    "poisson_bg_input.rate = net_dict[\"bg_rate\"] * ext_indegrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3bfefea6-5191-4846-8bd8-cb600559ff05",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m poisson_th\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m      5\u001b[0m     rate\u001b[38;5;241m=\u001b[39mnet_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     start\u001b[38;5;241m=\u001b[39mnet_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth_start\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m     stop\u001b[38;5;241m=\u001b[39m(net_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth_start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m net_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth_duration\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m th_connections \u001b[38;5;241m=\u001b[39m [right_populations[\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m8\u001b[39m]]\n\u001b[0;32m---> 11\u001b[0m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoisson_th\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth_connections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msyn_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/main-spack-instance-2402/spack/var/spack/environments/ebrains-24-04/.spack-env/view/lib/python3.8/site-packages/nest/ll_api.py:216\u001b[0m, in \u001b[0;36mstack_checker.<locals>.stack_checker_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_checker_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_debug():\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m         sr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/main-spack-instance-2402/spack/var/spack/environments/ebrains-24-04/.spack-env/view/lib/python3.8/site-packages/nest/lib/hl_api_connections.py:210\u001b[0m, in \u001b[0;36mConnect\u001b[0;34m(pre, post, conn_spec, syn_spec, return_synapsecollection)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;129m@check_stack\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mConnect\u001b[39m(pre, post, conn_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, syn_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_synapsecollection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Connect `pre` nodes to `post` nodes.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    :ref:`connectivity_concepts`\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     use_connect_arrays, pre, post \u001b[38;5;241m=\u001b[39m \u001b[43m_process_input_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# Converting conn_spec to dict, without putting it on the SLI stack.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     processed_conn_spec \u001b[38;5;241m=\u001b[39m _process_conn_spec(conn_spec)\n",
      "File \u001b[0;32m/srv/main-spack-instance-2402/spack/var/spack/environments/ebrains-24-04/.spack-env/view/lib/python3.8/site-packages/nest/lib/hl_api_connection_helpers.py:309\u001b[0m, in \u001b[0;36m_process_input_nodes\u001b[0;34m(pre, post, conn_spec)\u001b[0m\n\u001b[1;32m    305\u001b[0m         pre_is_nc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(post, NodeCollection):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# skip uniqueness check for connect_arrays compatible `conn_spec`\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m one_to_one_cspec \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(post):\n\u001b[1;32m    310\u001b[0m         post \u001b[38;5;241m=\u001b[39m NodeCollection(post)\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "#thalamus\n",
    "\n",
    "poisson_th = nest.Create(\"poisson_generator\")\n",
    "poisson_th.set(\n",
    "    rate=net_dict[\"th_rate\"],\n",
    "    start=net_dict[\"th_start\"],\n",
    "    stop=(net_dict[\"th_start\"] + net_dict[\"th_duration\"]),\n",
    ")\n",
    "    \n",
    "th_connections = [right_populations[4:8]]\n",
    "nest.Connect(poisson_th, th_connections, syn_spec={'weight': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef565614-de6a-4ad9-9daa-d89796a5e571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EBRAINS-24.04",
   "language": "python",
   "name": "ebrains-24.04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
